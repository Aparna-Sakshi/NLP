{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Assignment-4</h1>\n",
    "<h2>Conditional Random Fields</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn-crfsuite\n",
      "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from sklearn-crfsuite) (1.14.0)\n",
      "Collecting python-crfsuite>=0.8.3\n",
      "  Downloading python_crfsuite-0.9.7-cp37-cp37m-win_amd64.whl (154 kB)\n",
      "Requirement already satisfied: tqdm>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sklearn-crfsuite) (4.42.1)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.7-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: python-crfsuite, tabulate, sklearn-crfsuite\n",
      "Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6 tabulate-0.8.7\n"
     ]
    }
   ],
   "source": [
    "#installing sklearn-crfsuite\n",
    "!pip install sklearn-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from itertools import chain\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "import tensorflow as tf\n",
    "#from sklearn.cross_validation import cross_val_score\n",
    "#from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Preprocessing<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = list(open(\"hi-ud-train.conllu\", \"r\", encoding=\"utf-8\"))\n",
    "test_dataset = list(open(\"hi-ud-test .conllu\", \"r\", encoding=\"utf-8\"))\n",
    "#print(train_dataset)\n",
    "#print(test_dataset)\n",
    "train_data = []\n",
    "test_data= []\n",
    "sentence=[]\n",
    "for val in train_dataset[1:]: \n",
    "    val_list=val[:-1].split(',')  \n",
    "    #print(val_list)\n",
    "    if val_list[0]!='':       \n",
    "        sentence.append(val_list)        \n",
    "    else:\n",
    "        train_data.append(sentence)        \n",
    "        sentence=[]\n",
    "        \n",
    "sentence=[]\n",
    "for val in test_dataset[1:]: \n",
    "    val_list=val[:-1].split('\\t')  \n",
    "    #print(val_list)\n",
    "    if val_list[0]!='':       \n",
    "        sentence.append(val_list)        \n",
    "    else:\n",
    "        test_data.append(sentence)        \n",
    "        sentence=[]\n",
    "\n",
    "        \n",
    "        \n",
    "#print(train_data[0])\n",
    "#print(test_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Feature Extraction</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][1]\n",
    "    postag = sent[i][2]\n",
    "\n",
    "    features = {        \n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        \n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [postag for iD, word, postag in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [word for iD, word, postag in sent]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in train_data]\n",
    "y_train = [sent2labels(s) for s in train_data]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_data]\n",
    "y_test = [sent2labels(s) for s in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite import CRF\n",
    " \n",
    "model = CRF()\n",
    "model.fit(X_train, y_train)\n",
    "labels = list(model.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DET',\n",
       " 'PROPN',\n",
       " 'ADP',\n",
       " 'ADV',\n",
       " 'ADJ',\n",
       " 'NOUN',\n",
       " 'NUM',\n",
       " 'AUX',\n",
       " 'PUNCT',\n",
       " 'PRON',\n",
       " 'VERB',\n",
       " 'CCONJ',\n",
       " 'PART',\n",
       " 'COMMA',\n",
       " 'SCONJ',\n",
       " 'X']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Most likely Transitions</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------Train set---------------------\n",
      "--------------Top 10 likely transitions:--------------\n",
      "VERB   -> AUX     3.087001\n",
      "ADJ    -> NOUN    2.753777\n",
      "PROPN  -> PROPN   2.391956\n",
      "NOUN   -> ADP     2.237005\n",
      "PROPN  -> ADP     2.133795\n",
      "DET    -> NOUN    1.809328\n",
      "NUM    -> NOUN    1.714033\n",
      "PRON   -> ADP     1.640931\n",
      "ADJ    -> VERB    1.618387\n",
      "NOUN   -> VERB    1.582617\n",
      "---------------------------------------------------\n",
      "\n",
      "------------Top 10 unlikely transitions:--------------\n",
      "ADP    -> X       -0.558948\n",
      "CCONJ  -> VERB    -0.559135\n",
      "DET    -> PROPN   -0.660447\n",
      "AUX    -> VERB    -0.692009\n",
      "PROPN  -> DET     -0.774447\n",
      "ADP    -> SCONJ   -0.795802\n",
      "ADP    -> AUX     -0.813619\n",
      "AUX    -> ADJ     -0.851825\n",
      "ADP    -> COMMA   -0.853062\n",
      "ADP    -> CCONJ   -1.038824\n",
      "-----------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------Test set----------------------\n",
      "--------------Top 10 likely transitions:--------------\n",
      "VERB   -> AUX     2.300905\n",
      "ADJ    -> NOUN    1.916280\n",
      "PROPN  -> PROPN   1.825082\n",
      "PROPN  -> ADP     1.759003\n",
      "NOUN   -> ADP     1.744482\n",
      "AUX    -> PUNCT   1.530575\n",
      "DET    -> NOUN    1.318450\n",
      "NOUN   -> VERB    1.294255\n",
      "AUX    -> AUX     1.227393\n",
      "NUM    -> NOUN    1.070223\n",
      "------------------------------------------------------\n",
      "\n",
      "------------Top 10 unlikely transitions:--------------\n",
      "PART   -> AUX     -0.193051\n",
      "ADJ    -> ADJ     -0.201897\n",
      "NUM    -> AUX     -0.203706\n",
      "CCONJ  -> VERB    -0.204014\n",
      "NUM    -> ADP     -0.330041\n",
      "PUNCT  -> ADP     -0.358261\n",
      "VERB   -> ADJ     -0.366242\n",
      "PROPN  -> AUX     -0.411816\n",
      "ADP    -> AUX     -0.424969\n",
      "NOUN   -> DET     -0.489978\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "        \n",
    "modeltest= CRF()\n",
    "modeltest.fit(X_test,y_test)\n",
    "print(\"------------------------Train set---------------------\")\n",
    "print(\"--------------Top 10 likely transitions:--------------\")\n",
    "print_transitions(Counter(model.transition_features_).most_common(10))\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"\\n------------Top 10 unlikely transitions:--------------\")\n",
    "print_transitions(Counter(model.transition_features_).most_common()[-10:])\n",
    "print(\"-----------------------------------------------------\")\n",
    "print('\\n')\n",
    "print(\"------------------------Test set----------------------\")\n",
    "print(\"--------------Top 10 likely transitions:--------------\")\n",
    "print_transitions(Counter(modeltest.transition_features_).most_common(10))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"\\n------------Top 10 unlikely transitions:--------------\")\n",
    "print_transitions(Counter(modeltest.transition_features_).most_common()[-10:])\n",
    "print(\"-------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Predictions</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Accuracy----------------------\n",
      "                  0.8005540166204986\n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           X      0.000     0.000     0.000         0\n",
      "        PART      1.000     0.848     0.918        33\n",
      "       CCONJ      1.000     0.960     0.980        25\n",
      "       SCONJ      0.500     1.000     0.667         3\n",
      "         ADP      0.940     0.937     0.939       303\n",
      "         ADV      0.600     0.286     0.387        21\n",
      "         ADJ      0.558     0.713     0.626        94\n",
      "         DET      0.897     0.722     0.800        36\n",
      "        VERB      0.713     0.727     0.720        99\n",
      "        NOUN      0.732     0.809     0.768       324\n",
      "       COMMA      0.000     0.000     0.000         0\n",
      "       PROPN      0.603     0.528     0.563       144\n",
      "        PRON      0.817     0.754     0.784        65\n",
      "         NUM      0.950     0.760     0.844        25\n",
      "         AUX      0.866     0.935     0.899       138\n",
      "       PUNCT      1.000     0.828     0.906       134\n",
      "\n",
      "   micro avg      0.801     0.801     0.801      1444\n",
      "   macro avg      0.698     0.675     0.675      1444\n",
      "weighted avg      0.808     0.801     0.800      1444\n",
      "\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn_crfsuite import metrics\n",
    "from sklearn.metrics import recall_score\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"-----------------------Accuracy----------------------\")\n",
    "print(\"                 \",metrics.flat_accuracy_score(y_test, y_pred))\n",
    "print(\"-----------------------------------------------------\")\n",
    "\n",
    "\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:2])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))\n",
    "print(\"-----------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
